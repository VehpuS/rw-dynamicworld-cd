{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demonstrates the use of post-classification probability filters\n",
    "\n",
    "In classifying land cover, pixels are assigned probabilities for each land cover class that the pixel belongs in that land cover class. Oftentimes the land cover class with the highest probability is chosen as the final classification. However some land cover products choose to apply rules to these classification probabilities in order to increase the final accuracy, such as the [10m Sentinel-2 Based European Land Cover map](http://s2glc.cbk.waw.pl/extension) created by [Malinowski et al. 2020](https://www.mdpi.com/2072-4292/12/21/3523/htm).\n",
    "\n",
    "This notebook demonstrates post-classification probability filters that allows the user to generate rules based on performance on the training data. The notebook includes 4 steps\n",
    "\n",
    "1. Load Land Cover Classifications and Label Data\n",
    "2. Calculate Accuracy and Confusion Matrix for Original Classifications on Label Data\n",
    "3. Define Probability Filters and Apply to Land Cover Probabilities\n",
    "4. Calculate Accuracy and Confusion Matrix for Post-Filtered Classifications on Label Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load libraries and iniatilize Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from ipyleaflet import Map, basemaps\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# relative import for this folder hierarchy, credit: https://stackoverflow.com/a/35273613\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from wri_change_detection import preprocessing as npv\n",
    "from wri_change_detection import gee_classifier as gclass\n",
    "from wri_change_detection import post_classification_filters as pcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Iniatilize Earth Engine and Google Cloud authentication</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize earth engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Define a seed number to ensure reproducibility across random processes. This seed will be used in all subsequent sampling as well. We'll also define seeds for sampling the training, validation, and test sets.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seed=30\n",
    "random.seed(num_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Land Cover Classifications and Label Data\n",
    "\n",
    "\n",
    "<font size=\"4\">\n",
    "\n",
    "Define land cover classification image collection, with one image for each time period. Each image should have one band representing the classification in that pixel for one time period.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load collection\n",
    "#This collection represents monthly dynamic world classifications of land cover, later we'll squash it to annual\n",
    "dynamic_world_classifications_monthly = ee.ImageCollection('projects/wings-203121/assets/dynamic-world/v3-5_stack_tests/wri_test_goldsboro')\n",
    "\n",
    "#Get classes from first image\n",
    "dw_classes = dynamic_world_classifications_monthly.first().bandNames()\n",
    "dw_classes_str = dw_classes.getInfo()\n",
    "full_dw_classes_str = ['No Data']+dw_classes_str\n",
    "\n",
    "#Get dictionary of classes and values\n",
    "#Define array of land cover classification values\n",
    "dw_class_values = np.arange(1,10).tolist()\n",
    "dw_class_values_ee = ee.List(dw_class_values)\n",
    "#Create dictionary representing land cover classes and land cover class values\n",
    "dw_classes_dict = ee.Dictionary.fromLists(dw_classes, dw_class_values_ee)\n",
    "\n",
    "#Make sure the dictionary looks good\n",
    "print(dw_classes_dict.getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Define color palettes to map land cover</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_detection_palette = ['#ffffff', # no_data=0\n",
    "                              '#419bdf', # water=1\n",
    "                              '#397d49', # trees=2\n",
    "                              '#88b053', # grass=3\n",
    "                              '#7a87c6', # flooded_vegetation=4\n",
    "                              '#e49535', # crops=5\n",
    "                              '#dfc25a', # scrub_shrub=6\n",
    "                              '#c4291b', # builtup=7\n",
    "                              '#a59b8f', # bare_ground=8\n",
    "                              '#a8ebff', # snow_ice=9\n",
    "                              '#616161', # clouds=10\n",
    "]\n",
    "statesViz = {'min': 0, 'max': 10, 'palette': change_detection_palette};\n",
    "\n",
    "oneChangeDetectionViz = {'min': 0, 'max': 1, 'palette': ['696a76','ff2b2b']}; #gray = 0, red = 1\n",
    "consistentChangeDetectionViz = {'min': 0, 'max': 1, 'palette': ['0741df','df07b5']}; #blue = 0, pink = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Gather projection and geometry information from the land cover classifications</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_ee = dynamic_world_classifications_monthly.first().projection()\n",
    "projection = projection_ee.getInfo()\n",
    "crs = projection.get('crs')\n",
    "crsTransform = projection.get('transform')\n",
    "scale = dynamic_world_classifications_monthly.first().projection().nominalScale().getInfo()\n",
    "print('CRS and Transform: ',crs, crsTransform)\n",
    "\n",
    "geometry = dynamic_world_classifications_monthly.first().geometry().bounds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Convert the land cover collection to a multiband image, one band for each year, and reduce the monthly probability predictions to annual probablities.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define years to get annual classifications for\n",
    "years = np.arange(2016,2020)\n",
    "\n",
    "#Squash scenes from monthly to annual\n",
    "dynamic_world_classifications = npv.squashScenesToAnnualClassification(dynamic_world_classifications_monthly,years,method='median',image_name='dw_{}')\n",
    "\n",
    "#Squash scenes from monthly to annual\n",
    "dynamic_world_probabilites = npv.squashScenesToAnnualProbability(dynamic_world_classifications_monthly,years,method='median',image_name='dw_probs_{}')\n",
    "\n",
    "#Get image names \n",
    "dw_band_names = dynamic_world_classifications.aggregate_array('system:index').getInfo()\n",
    "#Convert to a multiband image and rename using dw_band_names\n",
    "dynamic_world_classifications_image = dynamic_world_classifications.toBands().rename(dw_band_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "Load label data to later compare land cover classification to label data. Export points of labelled data in order to compare to classifications later.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only labels for regions in Modesto CA, Goldsboro NC, the Everglades in FL, and one region in Brazil have been\n",
    "#uploaded to this collection\n",
    "labels = ee.ImageCollection('projects/wri-datalab/DynamicWorld_CD/DW_Labels')\n",
    "\n",
    "#Filter to where we have DW classifications\n",
    "labels_filtered = labels.filterBounds(dynamic_world_classifications_monthly.geometry())\n",
    "print('Number of labels that overlap classifications', labels_filtered.size().getInfo())\n",
    "\n",
    "#Save labels projection\n",
    "labels_projection = labels_filtered.first().projection()\n",
    "#Define geometry to sample points from \n",
    "labels_geometry = labels_filtered.geometry().bounds()\n",
    "\n",
    "#Compress labels by majority vote\n",
    "labels_filtered = labels_filtered.reduce(ee.Reducer.mode())\n",
    "#Remove pixels that were classified as no data\n",
    "labels_filtered = labels_filtered.mask(labels_filtered.neq(0))\n",
    "#Rename band\n",
    "labels_filtered = labels_filtered.rename(['labels'])\n",
    "\n",
    "\n",
    "#Sample points from label image at every pixel\n",
    "labelPoints = labels_filtered.sample(region=labels_geometry, projection=labels_projection, \n",
    "                                     factor=1, \n",
    "                                     seed=num_seed, dropNulls=True,\n",
    "                                     geometries=True)\n",
    "\n",
    "#Export sampled points\n",
    "labelPoints_export_name = 'goldsboro'\n",
    "labelPoints_assetID = 'projects/wri-datalab/DynamicWorld_CD/DW_LabelPoints_{}'\n",
    "labelPoints_description = 'DW_LabelPoints_{}'\n",
    "\n",
    "export_results_task = ee.batch.Export.table.toAsset(\n",
    "    collection=labelPoints, \n",
    "    description = labelPoints_description.format(labelPoints_export_name), \n",
    "    assetId = labelPoints_assetID.format(labelPoints_export_name))\n",
    "export_results_task.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Map land cover classifications and labels</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map years to check them out!\n",
    "center = [35.410769, -78.100163]\n",
    "zoom = 12\n",
    "Map1 = geemap.Map(center=center, zoom=zoom,basemap=basemaps.Esri.WorldImagery,add_google_map = False)\n",
    "Map1.addLayer(dynamic_world_classifications_image.select('dw_2016'),statesViz,name='2016 DW LC')\n",
    "Map1.addLayer(dynamic_world_classifications_image.select('dw_2017'),statesViz,name='2017 DW LC')\n",
    "Map1.addLayer(dynamic_world_classifications_image.select('dw_2018'),statesViz,name='2018 DW LC')\n",
    "Map1.addLayer(dynamic_world_classifications_image.select('dw_2019'),statesViz,name='2019 DW LC')\n",
    "Map1.addLayer(labels_filtered,statesViz,name='Labels')\n",
    "display(Map1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Accuracy and Confusion Matrix for Original Classifications on Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load label points\n",
    "labelPointsFC = ee.FeatureCollection(labelPoints_assetID.format('goldsboro'))\n",
    "\n",
    "#Save 2019 DW classifications and rename to \"dw_classifications\"\n",
    "dw_2019 = dynamic_world_classifications_image.select('dw_2019').rename('dw_classifications')\n",
    "\n",
    "#Sample the 2019 classifications at each label point\n",
    "labelPointsWithDW = dw_2019.sampleRegions(collection=labelPointsFC, projection = projection_ee, \n",
    "                                          tileScale=4, geometries=True)\n",
    "\n",
    "#Calculate confusion matrix, which we will use for an accuracy assessment\n",
    "originalErrorMatrix = labelPointsWithDW.errorMatrix('labels', 'dw_classifications')\n",
    "\n",
    "#Get the confusion matrix as a list\n",
    "errorMatrixValues = originalErrorMatrix.getInfo()\n",
    "\n",
    "#Print the confusion matrix with the class names as a dataframe\n",
    "#Axis 1 (the rows) of the matrix correspond to the actual values, and Axis 0 (the columns) to the predicted values.\n",
    "errorMatrixDf = pd.DataFrame(errorMatrixValues, index = full_dw_classes_str, columns = full_dw_classes_str)\n",
    "print('Axis 1 (the rows) of the matrix correspond to the actual values, and Axis 0 (the columns) to the predicted values.')\n",
    "display(errorMatrixDf)\n",
    "\n",
    "#You can also print further accuracy scores from the confusion matrix, however each one takes a couple minutes \n",
    "#to load\n",
    "print('Accuracy',originalErrorMatrix.accuracy().getInfo())\n",
    "# print('Consumers Accuracy',originalErrorMatrix.consumersAccuracy().getInfo())\n",
    "# print('Producers Accuracy',originalErrorMatrix.producersAccuracy().getInfo())\n",
    "# print('Kappa',originalErrorMatrix.kappa().getInfo())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Probability Filters and Apply to Land Cover Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'bare_ground': 8, 'built_area': 7, 'crops': 5, 'flooded_vegetation': 4, 'grass': 3, 'scrub': 6, 'snow_and_ice': 9, 'trees': 2, 'water': 1}\n",
    "\n",
    "#Define list of dictionaries to pass to applyProbabilityCutoffs\n",
    "#applyProbabilityCutoffs:\n",
    "# Function to apply a probability filter to land cover probabilities in each image of imageCollection. \n",
    "# The user defines which classes will be filtered and how to filter them in the params list.\n",
    "# The params list is a list of dictionaries, one for each class the user wants to filter.\n",
    "# The dictionaries in the params list is of the form {'class_name': String, 'class_value': Int, 'filter': String, 'threshold', Float}\n",
    "\n",
    "# If the filter is 'gt' or 'gte' (representing 'greater than' or 'greater than or equal to'), and if the pixel class probability greater than or greater \n",
    "#     than or equal to the threshold, then final classification is replaced by the value of that class.\n",
    "# If the filter is 'lt' or 'lte' (representing 'less than' or 'less than or equal to'), and if the pixel class probability less than or less than or\n",
    "#     equal to the threshold, and the pixel is in that class then final classification, then the final classification is replaced by\n",
    "#     the majority class of the neighborhood, where the neighborhood is a square kernel of size 1.\n",
    "\n",
    "#Here we will apply two filters: \n",
    "#First if the probability of the tree class is <0.5 and the pixel was classified as a tree, \n",
    "#then we replace it with the majority of the neighbor pixel classes\n",
    "\n",
    "#Second if the probability of the built-area class is >0.3, then the pixel is classified as built-area\n",
    "\n",
    "params = [{'class_name': 'trees', 'class_value': 2, 'filter': 'lt', 'threshold': 0.5},\n",
    "          {'class_name': 'built_area', 'class_value': 7, 'filter': 'gt', 'threshold': 0.3}]\n",
    "\n",
    "classifications_filtered = pcf.applyProbabilityCutoffs(dynamic_world_probabilites, params)\n",
    "image_names = classifications_filtered.aggregate_array('system:index')\n",
    "classifications_filtered = classifications_filtered.toBands().rename(image_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Accuracy and Confusion Matrix for Post-Filtered Classifications on Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load label points\n",
    "labelPointsFC = ee.FeatureCollection(labelPoints_assetID.format('goldsboro'))\n",
    "\n",
    "#Save 2019 post-filtered DW classifications and rename to \"dw_filterd_classifications\"\n",
    "classifications_filtered_2019 = classifications_filtered.select('dw_probs_2019').rename('dw_filterd_classifications')\n",
    "\n",
    "#Sample the 2019 classifications at each label point\n",
    "labelPointsWithFilteredDW = classifications_filtered_2019.sampleRegions(collection=labelPointsFC, \n",
    "                                                                        projection = projection_ee, \n",
    "                                                                        tileScale=4, geometries=True)\n",
    "\n",
    "#Calculate confusion matrix, which we will use for an accuracy assessment\n",
    "filteredErrorMatrix = labelPointsWithFilteredDW.errorMatrix('labels', 'dw_filterd_classifications')\n",
    "\n",
    "#Get the confusion matrix as a list\n",
    "filteredErrorMatrixValues = filteredErrorMatrix.getInfo()\n",
    "\n",
    "#Print the confusion matrix with the class names as a dataframe\n",
    "#Axis 1 (the rows) of the matrix correspond to the actual values, and Axis 0 (the columns) to the predicted values.\n",
    "filteredErrorMatrixDf = pd.DataFrame(filteredErrorMatrixValues, index = full_dw_classes_str, \n",
    "                                     columns = full_dw_classes_str)\n",
    "print('Axis 1 (the rows) of the matrix correspond to the actual values, and Axis 0 (the columns) to the predicted values.')\n",
    "display(filteredErrorMatrixDf)\n",
    "\n",
    "#You can also print further accuracy scores from the confusion matrix, however each one takes a couple minutes \n",
    "#to load\n",
    "print('Accuracy',filteredErrorMatrix.accuracy().getInfo())\n",
    "# print('Consumers Accuracy',originalErrorMatrix.consumersAccuracy().getInfo())\n",
    "# print('Producers Accuracy',originalErrorMatrix.producersAccuracy().getInfo())\n",
    "# print('Kappa',originalErrorMatrix.kappa().getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Map the classifications before and after the filtering, along with the probabilities for quality check.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map results to check them out!\n",
    "treesViz = {'min': 0, 'max': 1, 'palette': ['93ff8f','117e29']}; #light green = 0, dark green = 1\n",
    "builtAreaViz = {'min': 0, 'max': 1, 'palette': ['ff8f8f','c30000']}; #gray = 0, red = 1\n",
    "\n",
    "#Select probabilities for 2019\n",
    "dynamic_world_probabilites_2019 = dynamic_world_probabilites.filterDate('2019-01-01','2019-12-31').first()\n",
    "\n",
    "#Find where classifications changed after filtering\n",
    "changed_with_filter = dynamic_world_classifications_image.select('dw_2019').neq(classifications_filtered.select('dw_probs_2019'))\n",
    "\n",
    "Map2 = geemap.Map(center=center, zoom=zoom,basemap=basemaps.Esri.WorldImagery,add_google_map = False)\n",
    "Map2.addLayer(dynamic_world_probabilites_2019.select('trees'),treesViz,name='2019 DW Trees Probability')\n",
    "Map2.addLayer(dynamic_world_probabilites_2019.select('built_area'),builtAreaViz,name='2019 DW Built Area Probability')\n",
    "Map2.addLayer(dynamic_world_classifications_image.select('dw_2019'),statesViz,name='2019 DW LC')\n",
    "Map2.addLayer(classifications_filtered.select('dw_probs_2019'),statesViz,name='2019 DW LC Post Filter')\n",
    "Map2.addLayer(changed_with_filter,oneChangeDetectionViz,name='Changed with Filter')\n",
    "display(Map2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
